# Local testing scenario configuration
# This file is for local docker-compose testing with the generate_compose.py tool
#
# Usage:
#   1. Build your Docker images locally or use published images
#   2. python generate_compose.py --scenario scenarios/scenario-docker-local.toml
#   3. cp .env.example .env  # Edit with your API keys
#   4. mkdir -p output
#   5. docker compose up --abort-on-container-exit

[green_agent]
# For local testing, use 'build' to build from local Dockerfile
build = { context = ".", dockerfile = "src/green_car_bench_agent/Dockerfile.car-bench-evaluator" }
# Environment variables for the green agent
env = { GEMINI_API_KEY = "${GEMINI_API_KEY}", LOGURU_LEVEL = "${LOGURU_LEVEL}" }

[[participants]]
# For local testing, use 'build' to build from local Dockerfile
build = { context = ".", dockerfile = "src/purple_car_bench_agent/Dockerfile.car-bench-agent" }
name = "agent"
# Environment variables - include all API keys the agent might need
# AGENT_LLM: Specifies which LLM model to use (works in both local and GitHub Actions)
env = { ANTHROPIC_API_KEY = "${ANTHROPIC_API_KEY}", OPENAI_API_KEY = "${OPENAI_API_KEY}", GEMINI_API_KEY = "${GEMINI_API_KEY}", AGENT_LLM = "anthropic/claude-haiku-4-5-20251001", LOGURU_LEVEL = "${LOGURU_LEVEL}" }
# Command arguments (optional, AGENT_LLM env var is preferred for production)
command_args = ["--agent-llm", "anthropic/claude-haiku-4-5-20251001"]

[config]
# CAR-bench specific configuration
# Controls which tasks to run and how many trials per task
num_trials = 2
tasks_base_start_index = 0
tasks_base_end_index = 2
tasks_hallucination_start_index = 0
tasks_hallucination_end_index = 2
tasks_disambiguation_start_index = 0
tasks_disambiguation_end_index = 2
max_steps = 20  # Maximum conversation turns per task
